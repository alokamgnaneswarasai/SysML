{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 5, 0, -1, 2, 2, -1, 16, 5, 0, -1, 2, 2, -1, 400, 120, -1, 120, 84, -1, 84, 10, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Read config.json file\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Extract necessary values from config\n",
    "layers = config[\"layers\"]\n",
    "embedding_size = config[\"embedding_size\"]\n",
    "\n",
    "\n",
    "\n",
    "def parse_layers_from_arch(arch):\n",
    "    arch = {\n",
    "    'LeNet5': [('C', 6, 5, 'not_same', 3),\n",
    "                ('M',2,2),\n",
    "                ('C', 16, 5, 'not_same'),\n",
    "                ('M',2,2),\n",
    "                ('fc' , 400 , 120 , ),\n",
    "                 ('fc' , 120 , 84),\n",
    "                ('fc' , 84 , 10)] ,\n",
    "    }\n",
    "    \n",
    "    layers = arch['LeNet5']\n",
    "    layer2vec = [0] * embedding_size\n",
    "    index = 0\n",
    "    for layer in layers : \n",
    "        if layer[0] == 'C' : \n",
    "             layer2vec[index] = layer[1]\n",
    "             layer2vec[index+1] = layer[2]\n",
    "             layer2vec[index+2] = config[layer[3]] * (layer[2]) // 2\n",
    "             layer2vec[index+3] = config[\"end\"]\n",
    "             index += 4\n",
    "        elif layer[0] == 'M' : \n",
    "             layer2vec[index] = layer[1]\n",
    "             layer2vec[index+1] = layer[2]\n",
    "             layer2vec[index+2] = config[\"end\"]\n",
    "             index += 3\n",
    "        elif layer[0] == 'fc' : \n",
    "            layer2vec[index] = layer[1]\n",
    "            layer2vec[index+1] = layer[2]\n",
    "            layer2vec[index+2] = config[\"end\"]\n",
    "            index += 3\n",
    "        else : \n",
    "            raise ValueError(\"Invalid layer type\")\n",
    "    print(layer2vec)\n",
    "    \n",
    "\n",
    "\n",
    "parse_layers_from_arch(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1:\n",
      "DataFrame 2:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# fead all the files in the folder results\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the entire content of the CSV file into a string\n",
    "with open(\"Results/CNN6/NeuroSim_Results_Each_Epoch/NeuroSim_Breakdown_Epock_0.csv\", 'r') as file:\n",
    "    csv_content = file.read()\n",
    "\n",
    "# Split the content into individual CSV files based on a delimiter\n",
    "delimiter = \"\\n\\n\"  # Replace this with the appropriate delimiter/pattern\n",
    "individual_csvs = csv_content.split(delimiter)\n",
    "\n",
    "# Iterate through the individual CSVs, skipping the first one as it may be incomplete\n",
    "\n",
    "csv = []\n",
    "for i, csv_data in enumerate(individual_csvs[1:], start=1):\n",
    "    # Write each individual CSV data to a separate file\n",
    "    with open(f\"csv_{i}.csv\", 'w') as outfile:\n",
    "        outfile.write(csv_data)\n",
    "\n",
    "    # Read the individual CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(f\"csv_{i}.csv\")\n",
    "    print(f\"DataFrame {i}:\")\n",
    "    csv.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10.445700\n",
       "1     3.464200\n",
       "2     0.116853\n",
       "3     0.027138\n",
       "4    14.053800\n",
       "Name:  latency_FW(s), dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv[0][' latency_FW(s)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.045570\n",
       "1    0.015174\n",
       "2    0.003957\n",
       "3    0.000058\n",
       "4    0.064760\n",
       "Name:  energy_FW(J), dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv[0][' energy_FW(J)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
